xt[ix.more(ix),]
ix["2018-08"]
ix["2018-08",]
ix["2018-08"]
xt["2018-08"]
xt["2018-08-06::2018-08-09"]
summary(dtdt)
sd(dtdt)
X11();plot(dtdt, type="l")
getwd()
save.image("Robintrack.RData")
library(quantmod)
home = "/mnt/WanChai/Dropbox/GITHUB_REPO/Robinhood_at_a_glance"
utils = "/mnt/WanChai/Dropbox/GITHUB_REPO/Robinhood_at_a_glance/utils"
plot_dir = "/mnt/WanChai/Dropbox/GITHUB_REPO/Robinhood_at_a_glance/plots"
dat_dir = "/mnt/WanChai/Dropbox/GITHUB_REPO/Robinhood_at_a_glance/robintrack_popularity_export"
dat_dir = "/mnt/WanChai/Dropbox/AlgoTrading/Robinhood/robintrack_popularity_export"
setwd(home)
source(paste(utils, "/Fun.R", sep=""))
load("Robintrack.RData")
ls()
len(ls(envir=data_env))
length(ls(envir=data_env))
?cut
tdt = index(data_env$AAPL)
head(tdt, 200)
dtdt = as.integer(diff(tdt)) # delta in seconds
head(dtdt)
summary(dtdt)
granu = cut(dtdt, breaks=c(0, 60*5, 60*30,60*60,12*60*60,24*60*60,Inf), include.lowest=FALSE, right=TRUE)
head(granu)
granu = cut(dtdt, breaks=c(0, 60*5, 60*30,60*60,12*60*60,24*60*60,Inf), labels=c("5min", "halfhr", "1hr", "halfday", "1day", "morethan"), include.lowest=FALSE, right=TRUE)
head(granu)
table(granu)
source(paste(utils, "/Fun.R", sep=""))
# ===== Data exploration ============================================
ll = sweep_env(data_env, xts_time_spacing)
len(ll)
library()
library(goodies)
len(ll)
head(ll[[330]])
sum(head(ll[[330]]))
ll[[330]]
ll[[330]][1]
ll[[330]]["5min"]
pct_1hr = sapply(ll, function(.x) .x[["1hr"]] / sum(.x))
X11();hist(pc_1hr, breaks=30)
X11();hist(pct_1hr, breaks=30)
le = ll[[1234]]
le
names(le)
attr(le)
attributes(le)
dimnames(le)
str(le)
le$granu
xt = data_env$AAPL
colnames(xt)
source(paste(utils, "/Fun.R", sep=""))
# ===== Data exploration ============================================
ll = sweep_env(data_env, xts_time_spacing)
ll[[1234]]
ll[[1234]][["tkr"]]
ll[[1234]][["granu"]]
source(paste(utils, "/Fun.R", sep=""))
# ===== Data exploration ============================================
ll = sweep_env(data_env, xts_time_spacing)
ll[[1234]]
pct_1hr = sapply(ll, function(.x) .x[["granu"]][["1hr"]] / sum(.x[["granu"]]))
X11();hist(pct_1hr)
X11();hist(pct_1hr, breaks=30)
head(pct_1hr, 30)
ix=which(pct_1hr < 0.1)
ix
sapply(ix, function(.i)ll[[.i]][["tkr"]])
xt = data_env$ADRD
dim(xt)
head(xt, 100)
tdt=index(xt)
dtdt = as.integer(diff(tdt)) # delta in seconds
granu = cut(dtdt, breaks=c(0, 60*5, 60*30,60*60,12*60*60,24*60*60,Inf),
labels=c("5min", "halfhr", "1hr", "halfday", "1day", "morethan"),
include.lowest=FALSE, right=TRUE)
tb = table(granu)
tb
head(dtdt, 100)
head(tdt)
diff(tdt, 100)
diff(tdt, 10)
head(diff(tdt), 10)
?diff.xts
xt = data_env$AAPL
tdt = index(xt)
head(diff(tdt))
head(tdt)
class(tdt)
xt = data_env$ADRD
head(xt)
tdt = index(xt)
head(diff(tdt))
class(diff(tdt))
?difftime
dtdt=difftime(tdt, units="secs")
difftime(tdt[1], tdt[2], units="secs")
?head
ii = c(1,2,3,4,5,6,7,8,9)
head(ii, 1)
head(ii, -1)
tail(ii, -1)
head(xt)
tdt = index(xt)
tmp = difftime(head(tdt,-1), tail(tdt,-1))
head(tmp, 10)
tmp = difftime(tail(tdt,-1), head(tdt,-1), units="secs")
head(tmp)
class(tmp)
dtdt = as.integer(tmp) # delta in seconds
head(dtdt)
granu = cut(dtdt, breaks=c(0, 60*5, 60*30,60*60,12*60*60,24*60*60,Inf),
labels=c("5min", "halfhr", "1hr", "halfday", "1day", "morethan"),
include.lowest=FALSE, right=TRUE)
tb = table(granu)
tb
source(paste(utils, "/Fun.R", sep=""))
# ===== Data exploration ============================================
ll = sweep_env(data_env, xts_time_spacing)
pct_1hr = sapply(ll, function(.x) .x[["granu"]][["1hr"]] / sum(.x[["granu"]]))
X11();hist(pct_1hr, breaks=30)
pct_5min = sapply(ll, function(.x) .x[["granu"]][["5min"]] / sum(.x[["granu"]]))
X11();hist(pct_5min, breaks=30)
ix = which(pct_5min > 0.3)
ix
sapply(ix, function(.i)ll[[.i]][["tkr"]])
# Notice some ticker has more than 40% deltas in the 5min bucket, smells problem.
# Who are these ?
sapply(which(pct_5min > 0.4), function(.i)ll[[.i]][["tkr"]])
xt = data_env$EBR
head(xt)
head(data_env$GEF)
head(data_env$HEI)
head(data_env$HVT)
head(data_env$LEN)
head(data_env$MKC)
head(data_env$PBR)
head(data_env$STZ)
head(data_env$WSO)
X11();plot(data_env$STZ["2018-05::2018-06"])
X11();plot(data_env$STZ["2018-05"])
X11();plot(data_env$STZ["2018-05-02::2018-05-10"])
X11();plot(data_env$STZ["2018-05-02::2018-05-07"])
?cut
source(paste(utils, "/Fun.R", sep=""))
# ===== Data exploration ============================================
ll = sweep_env(data_env, xts_time_spacing)
pct_1hr = sapply(ll, function(.x) .x[["granu"]][["1hr"]] / sum(.x[["granu"]]))
X11();hist(pct_1hr, breaks=30)
install.packages("PSF")
install.packages("gt")
library(gt)
library(tidyverse)
library(glue)
start_date <- "2010-06-07"
end_date <- "2010-06-14"
sp500 %>%
dplyr::filter(date >= start_date & date <= end_date) %>%
dplyr::select(-adj_close) %>%
gt() %>%
tab_header(
title = "S&P 500",
subtitle = glue::glue("{start_date} to {end_date}")
) %>%
fmt_date(
columns = vars(date),
date_style = 3
) %>%
fmt_currency(
columns = vars(open, high, low, close),
currency = "USD"
) %>%
fmt_number(
columns = vars(volume),
suffixing = TRUE
)
head(sp500)
class(sp500)
ls()
X11();hist(pct_1hr, breaks=30)
X11();hist(pct_5min, breaks=30)
xts_time_spacing(data_env$STZ)
tmp = xts_time_spacing(data_env$STZ)
tmp[["granu"]]
which.max(tmp[["granu"]])
# Observation : very few. But there are some tickers with more than 40% deltas in the 5min bucket.
# That smells trouble. Who are these ?
sapply(which(pct_5min > 0.3), function(.i)ll[[.i]][["tkr"]])
# Observation : very few. But there are some tickers with more than 40% deltas in the 5min bucket.
# That smells trouble. Who are these ?
sapply(which(pct_5min > 0.2), function(.i)ll[[.i]][["tkr"]])
# Observation : very few. But there are some tickers with more than 40% deltas in the 5min bucket.
# That smells trouble. Who are these ?
sapply(which(pct_5min > 0.1), function(.i)ll[[.i]][["tkr"]])
head(xt)
mean(xt)
mean(xt[,1])
?mean.xts
xts.mean
?mean
?median
median(xt)
source(paste(utils, "/Fun.R", sep=""))
source(paste(utils, "/Fun.R", sep=""))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold)
source(paste(utils, "/Fun.R", sep=""))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold)
len(ll1)
ll1[[1234]]
table(sapply(ll1, function(.x).x[[1]]))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold, 0)
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold, thres=0)
source(paste(utils, "/Fun.R", sep=""))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold, thres=0)
source(paste(utils, "/Fun.R", sep=""))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold, thres=0)
table(sapply(ll1, function(.x).x[[1]]))
table(sapply(ll1, function(.x).x[[2]]))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold, thres=100)
table(sapply(ll1, function(.x).x[[2]]))
table(sapply(ll1, function(.x).x[[1]]))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold, thres=1e-2)
table(sapply(ll1, function(.x).x[[1]]))
table(sapply(ll1, function(.x).x[[2]]))
tail(xt, 10)
mean(tail(xt, 10))
mean(tail(xt, 30))
tail(xt, 30)
source(paste(utils, "/Fun.R", sep=""))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold, thres=1e-2)
table(sapply(ll1, function(.x).x[[3]]))
source(paste(utils, "/Fun.R", sep=""))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold, thres=1e-2)
table(sapply(ll1, function(.x).x[[1]]))
table(sapply(ll1, function(.x).x[[2]]))
table(sapply(ll1, function(.x).x[[3]]))
source(paste(utils, "/Fun.R", sep=""))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold, thres=1e-2)
table(sapply(ll1, function(.x).x[[1]]))
table(sapply(ll1, function(.x).x[[2]]))
table(sapply(ll1, function(.x).x[[3]]))
source(paste(utils, "/Fun.R", sep=""))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold, thres=1e-2)
table(sapply(ll1, function(.x).x[["ave.below"]]))
table(sapply(ll1, function(.x).x[["ave.below"]]))
table(sapply(ll1, function(.x).x[["med.below"]]))
table(sapply(ll1, function(.x).x[["latest.n.below"]]))
ix.ave = sapply(ll1, function(.x).x[["ave.below"]])
table(ix.ave)
head(ix.ave)
which(ix.ave)
sapply(ix.ave, function(.i)ll1[[.i]][["tkr"]])
source(paste(utils, "/Fun.R", sep=""))
# How many tickers have near zero holding over the entire time period (2 yrs)?
ll1 = sweep_env(data_env, holding_below_threshold, thres=1e-2)
ix.ave = sapply(ll1, function(.x).x[["ave.below"]])
table(ix.ave)
table(sapply(ll1, function(.x).x[["med.below"]]))
table(sapply(ll1, function(.x).x[["latest.n.below"]]))
sapply(ix.ave, function(.i)ll1[[.i]][["tkr"]])
ll1[[1]]
ll1[[1]][["tkr"]]
ix.ave
sapply(which(ix.ave), function(.i)ll1[[.i]][["tkr"]])
ix.ave = sapply(ll1, function(.x).x[["ave.below"]])
table(ix.ave)
ix.med = sapply(ll1, function(.x).x[["med.below"]])
table(ix.med)
ix.latest = sapply(ll1, function(.x).x[["latest.n.below"]])
table(ix.latest)
sapply(which(ix.latest), function(.i)ll1[[.i]][["tkr"]])
sapply(which(ix.med), function(.i)ll1[[.i]][["tkr"]])
sapply(which(ix.ave), function(.i)ll1[[.i]][["tkr"]])
head(xt)
tmp =diff(xt)
head(tmp)
class(tmp)
tail(tmp)
tail(tmp, 50)
?diff
abrupt_change = function(xt, thres=10000) {
tkr = colnames(xt)[1]
dx = diff(xt, lag=1)
big.change = any(abs(dx) > thres)
return(list(tkr=tkr, big.change=big.change))
}
source(paste(utils, "/Fun.R", sep=""))
# Any abrupt change in user holding?
# -- step change from X to zero, or from zero to X
ll2 = sweep_env(data_env, abrupt_change, thres=10000)
ix.big.ch = sapply(ll2, function(.x).x[["big.change"]])
which(ix.big.ch)
sapply(which(ix.big.ch), function(.i)ll2[[.i]][["tkr"]])
# Any abrupt change in user holding?
# -- step change from X to zero, or from zero to X
ll2 = sweep_env(data_env, abrupt_change, thres=100000)
ix.big.ch = sapply(ll2, function(.x).x[["big.change"]])
sapply(which(ix.big.ch), function(.i)ll2[[.i]][["tkr"]])
# Any abrupt change in user holding?
# -- step change from X to zero, or from zero to X
ll2 = sweep_env(data_env, abrupt_change, thres=50000)
ix.big.ch = sapply(ll2, function(.x).x[["big.change"]])
sapply(which(ix.big.ch), function(.i)ll2[[.i]][["tkr"]])
# Any abrupt change in user holding?
# -- step change from X to zero, or from zero to X
ll2 = sweep_env(data_env, abrupt_change, thres=20000)
ix.big.ch = sapply(ll2, function(.x).x[["big.change"]])
sapply(which(ix.big.ch), function(.i)ll2[[.i]][["tkr"]])
X11();plot(data_env$GNUS)
X11();plot(data_env$IGC)
X11();plot(data_env$INPX)
X11();plot(data_env$ACB)
X11();plot(data_env$NKLA)
X11();plot(data_env$IGC) #
X11();plot(data_env$UBER) # sharp rise is real
X11();plot(data_env$UCO) # no issue
X11();plot(data_env$USO) # no issue
X11();plot(data_env$WORK) # not sure why such sharp drop
ls(data_env)
len(ls(data_env))
head(sp500)
ls()
listenv()
search()
str(sp500)
sp500
head(sp500)
tail(sp500)
X11();plot(sp500)
X11();plot(sp500[,7])
X11();plot(sp500["adj_close"])
ls()
sp500 %>% View()
str(sp500)
tibble(
x = 1:5,
y = 1,
z = x ^ 2 + y
)
XX=tibble(
x = 1:5,
y = 1,
z = x ^ 2 + y
)
SP5 = sp500
View(XX)
View(SP5)
gt_tbl <-
gt_tbl %>%
cols_move_to_start(
columns = vars(Year, Month, Day)
) %>%
cols_label(
Ozone = html("Ozone,<br>ppbV"),
Solar.R = html("Solar R.,<br>cal/m<sup>2</sup>"),
Wind = html("Wind,<br>mph"),
Temp = html("Temp,<br>&deg;F")
)
islands_tbl <-
dplyr::tibble(
name = names(islands),
size = islands
) %>%
dplyr::arrange(desc(size)) %>%
dplyr::slice(1:10)
islands_tbl
gt_tbl <- gt(data = islands_tbl)
gt_tbl
tab_html <-
gtcars %>%
dplyr::select(mfr, model, msrp) %>%
dplyr::slice(1:5) %>%
gt() %>%
tab_header(
title = md("Data listing from **gtcars**"),
subtitle = md("`gtcars` is an R dataset")
) %>%
as_raw_html()
tab_html
as_raw_html(gt_tbl)
# 2. Top holdings
df = as.data.frame(t(sapply(ll, latest_stat, "2020-03-20")))
#
setwd(home)
# Aggregate the hourly data to daily and weekly and put them in a list
ll = sweep_env(data_env, day_wk_aggregator)
# Check + statistics on each ticker dataset
cnt = table(sapply(ll, function(.s) nrow(.s[["y_daily"]])))
sum(cnt[which(as.integer(names(cnt)) > 365)]) / len(tkr)
# [1] 0.8450455
# ==> 84% of the tickers have more than 1 yr of data
table(sapply(ll, function(.s) nrow(.s[["dy_daily"]])))
# 2. Top holdings
df = as.data.frame(t(sapply(ll, latest_stat, "2020-03-20")))
df[,"tkr"] = as.character(df[,"tkr"])
df[,"base_holding"] = as.numeric(df[,"base_holding"])
df[,"cur_holding"] = as.numeric(df[,"cur_holding"])
df[,"pct_change"] = 100*(df[,"cur_holding"] / df[,"base_holding"] - 1)
df = df[order(df[,"cur_holding"], decreasing = TRUE),]
head(df, 20)
# Get all CSV file names
nm = list.files(path=dat_dir, all.files=FALSE, include.dirs=FALSE)
head(nm)
read.csv(nm[1], header=TRUE)
setwd(dat_dir)
read.csv(nm[1], header=TRUE)
head(read.csv(nm[1], header=TRUE))
nm = nm[3:length(nm)]
(N = length(nm))
# Build vector of ticker symbols
tkr = sapply(strsplit(x=nm, split="\\."), parse_ticker)
# Read CSV files, convert them to xts objects, save them to the data_env environment
setwd(dat_dir)
rm(data_env)
ls(envir=data_env)
data_env = new.env()
Len = sapply(nm, read_convert_save2env, data_env=data_env)
# time series lengths
X11();hist(Len)
# time series lengths
X11();hist(Len, breaks=35)
# time series lengths
X11();hist(Len, breaks=35, xlab="No of observations in a CSV file", main="Distribution of Time Series Lengths")
# time series lengths
setwd(home)
png("LengthDistrib.png", width=640, height=480)
hist(Len, breaks=35, xlab="No of observations in a CSV file", main="Distribution of Time Series Lengths")
dev.off()
summary(Len)
# Data issue : some time series are much longer than others. Duplicate entries.
which(Len > 25000)
# Look at their time steps =================================================
ll = sweep_env(data_env, xts_time_spacing)
# Over all the tickers, what percent of the time intervals falls in the half-hr to 1 hr bucket?
pct_1hr = sapply(ll, function(.x) .x[["granu"]][["1hr"]] / sum(.x[["granu"]]))
X11();hist(pct_1hr, breaks=30)
png("OneHrIntervalDistrib.png", width=640, height=480)
hist(pct_1hr, breaks=30, xlab="Fraction of 1-hr Intervals", main="Distribution of One-Hour Intervals")
dev.off()
getwd()
# Over all the tickers, what percent of the time intervals falls in the 0 to 5-min bucket?
pct_5min = sapply(ll, function(.x) .x[["granu"]][["5min"]] / sum(.x[["granu"]]))
png("5minIntervalDistrib.png", width=640, height=480)
hist(pct_5min, breaks=30, xlab="Fraction of 5-min Intervals", main="Distribution of 5-min Intervals")
dev.off()
# They all seem to be outer-joined by two different tickers together. Two adjacent
# observations are just seconds apart, and they fluctuate in identifical manner.
# indiv check :
xts_time_spacing(data_env$STZ)
sapply(which(ix.ave), function(.i)ll1[[.i]][["tkr"]])
len(sapply(which(ix.ave), function(.i)ll1[[.i]][["tkr"]]))
len(sapply(which(ix.med), function(.i)ll1[[.i]][["tkr"]]))
rnd_samp=sapply(which(ix.med), function(.i)ll1[[.i]][["tkr"]])
rnd_samp
rnd_samp[sample(rnd_samp, size=10, replace=FALSE)]
sample(rnd_samp, size=10, replace=FALSE)
sample(rnd_samp, size=10, replace=FALSE)
sample(rnd_samp, size=10, replace=FALSE)
# Any abrupt change in user holding?
# -- step change from X to zero, or from zero to X
ll2 = sweep_env(data_env, abrupt_change, thres=20000)
ix.big.ch = sapply(ll2, function(.x).x[["big.change"]])
sapply(which(ix.big.ch), function(.i)ll2[[.i]][["tkr"]])
X11();plot(data_env$ACB) # stock split ?
getwd()
png("ACB.png", width=640, height=480)
plot(data_env$ACB) # stock split ?
dev.off()
png("GNUS.png", width=640, height=480)
plot(data_env$GNUS) # sharp rise is real !
dev.off()
png("IGC.png", width=640, height=480)
plot(data_env$IGC) # chunk of data is missing
dev.off()
png("INPX.png", width=640, height=480)
plot(data_env$INPX) # chunk of data is missing
dev.off()
png("NKLA.png", width=640, height=480)
plot(data_env$NKLA) # sharp rise is real
dev.off()
png("UBER.png", width=640, height=480)
plot(data_env$UBER) # no issue
dev.off()
png("UCO.png", width=640, height=480)
plot(data_env$UCO) # problem with one or two data points
dev.off()
png("USO.png", width=640, height=480)
plot(data_env$USO) # not sure why such sharp drop
dev.off()
png("WORK.png", width=640, height=480)
plot(data_env$WORK) # coincide with price gap down
dev.off()
