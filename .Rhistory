addNodeColors(colorAttr = 'group', colorPal = 'Set1')
sig
library(nnet)
?nnet
library(igraph)
library(sigmaNet)
library(magrittr)
data(lesMis)
l <- layout_nicely(lesMis)
sig <- sigmaFromIgraph(graph = lesMis, layout = l)
sig
# library
library(igraph)
# create data:
links=data.frame(
source=c("A","A", "A", "A", "A","J", "B", "B", "C", "C", "D","I"),
target=c("B","B", "C", "D", "J","A","E", "F", "G", "H", "I","I")
)
# Turn it into igraph object
network <- graph_from_data_frame(d=links, directed=T)
# Count the number of degree for each node:
deg <- degree(network, mode="all")
X11()
plot(network, vertex.size=deg*6, vertex.color=rgb(0.1,0.7,0.8,0.5) )
# create data:
links <- data.frame(
source=c("A","A", "A", "A", "A","J", "B", "B", "C", "C", "D","I"),
target=c("B","B", "C", "D", "J","A","E", "F", "G", "H", "I","I"),
importance=(sample(1:4, 12, replace=T))
)
nodes <- data.frame(
name=LETTERS[1:10],
carac=c( rep("young",3),rep("adult",2), rep("old",5))
)
# Turn it into igraph object
network <- graph_from_data_frame(d=links, vertices=nodes, directed=F)
# Make a palette of 3 colors
library(RColorBrewer)
coul  <- brewer.pal(3, "Set1")
# Create a vector of color
my_color <- coul[as.numeric(as.factor(V(network)$carac))]
X11()
plot(network, vertex.color=my_color)
# Create data
data <- matrix(sample(0:1, 400, replace=TRUE, prob=c(0.8,0.2)), nrow=20)
network <- graph_from_adjacency_matrix(data , mode='undirected', diag=F )
X11()
par(mfrow=c(2,2), mar=c(1,1,1,1))
plot(network, layout=layout.sphere, main="sphere")
plot(network, layout=layout.fruchterman.reingold, main="fruchterman.reingold")
# create data:
links=data.frame(
source=c("A","A", "A", "A", "A","J", "B", "B", "C", "C", "D","I"),
target=c("B","B", "C", "D", "J","A","E", "F", "G", "H", "I","I")
)
# Turn it into igraph object
network <- graph_from_data_frame(d=links, directed=T)
# Count the number of degree for each node:
deg <- degree(network, mode="all")
deg
# create data:
links <- data.frame(
source=c("A","A", "A", "A", "A","J", "B", "B", "C", "C", "D","I"),
target=c("B","B", "C", "D", "J","A","E", "F", "G", "H", "I","I"),
importance=(sample(1:4, 12, replace=T))
)
links
?graph_from_data_frame
## A simple example with a couple of actors
## The typical case is that these tables are read in from files....
actors <- data.frame(name=c("Alice", "Bob", "Cecil", "David",
"Esmeralda"),
age=c(48,33,45,34,21),
gender=c("F","M","F","M","F"))
actors
relations <- data.frame(from=c("Bob", "Cecil", "Cecil", "David",
"David", "Esmeralda"),
to=c("Alice", "Bob", "Alice", "Alice", "Bob", "Alice"),
same.dept=c(FALSE,FALSE,TRUE,FALSE,FALSE,TRUE),
friendship=c(4,5,5,2,1,1), advice=c(4,5,5,4,2,3))
relations
g <- graph_from_data_frame(relations, directed=TRUE, vertices=actors)
print(g, e=TRUE, v=TRUE)
g
X11()
plot(g)
tkplot
tkplot(g)
tkplot(network)
E(network)
E(network)$color
E(network)$color <- "grey"
tkplot(network)
E(network)$color <- "red"
tkplot(network)
V(network)
V(network)$color <-"white"
tkplot(network)
V(network)$color
E(network)$color
?E
str(network)
?nls
home = getwd()
homne
home
home = getwd()
home
today = Sys.Date()
today.ch = as.character(today)
if ( file.exists("CoronaV.RData") ) load("CoronaV.RData")
ls()
home = getwd()
home
if ( file.exists("CoronaV.RData") ) load("CoronaV.RData")
ls()
install.packages("pacman")
pacman::p_load_gh(c(
"trinker/textshape",
"trinker/coreNLPsetup",
"trinker/parsent"
))
library(parsent)
pacman::p_load(parsent, magrittr)
txt <- c(
"Really, I like chocolate because it is good. It smells great.",
"Robots are rather evil and most are devoid of decency.",
"He is my friend.",
"Clifford the big red dog ate my lunch.",
"Professor Johns can not teach",
"",
NA
)
if(!exists('parse_ann')) {
parse_ann <- parse_annotator()
}
(x <- parser(txt, parse.annotator = parse_ann))
X11()
par(mar = c(0,0,0,.7) + 0.2)
plot(x[[2]])
X11()
par(
mfrow = c(3, 2),
mar = c(0,0,1,1) + 0.1
)
invisible(lapply(x[1:5], plot))
get_phrase_type(x, "NP") %>% take() %>% get_leaves()
get_phrase_type_regex(x, "VP") %>%
take() %>%
get_phrase_type_regex("(VB|MD)") %>%
take() %>%
get_leaves()
get_phrase_type_regex(x, "VP") %>%
take() %>%
get_phrase_type_regex("NP") %>%
take() %>%
get_leaves()
get_phrase_type(x, "NP")
res = get_phrase_type(x, "NP")
class(res)
len(res)
length(res)
res[[1]]
get_leaves(res[[1]])
get_leaves((res[[1]]))
get_leaves((res[[2]]))
get_leaves((res[[3]]))
x
txt
get_leaves((res[[4]]))
get_leaves((res[[5]]))
get_leaves((res[[6]]))
get_leaves((res[[7]]))
x = matrix(sample(0:9, 20, replace=TRUE), nrow=5)
x
colSums(x)
library(goodies)
library(quantmod)
library(goodies)
library(quantmod)
home = "/mnt/WanChai/Dropbox/GITHUB_REPO/Monumental_Day"
setwd(home)
home = "/mnt/WanChai/Dropbox/GITHUB_REPO/Monumental_Day"
setwd(home)
library(goodies)
library(quantmod)
home = "/mnt/WanChai/Dropbox/GITHUB_REPO/Monumental_Day"
setwd(home)
library(quantmod)
library(xtable)
home = "/mnt/WanChai/Dropbox/GITHUB_REPO/Robinhood_at_a_glance"
utils = "/mnt/WanChai/Dropbox/GITHUB_REPO/Robinhood_at_a_glance/utils"
plot_dir = "/mnt/WanChai/Dropbox/GITHUB_REPO/Robinhood_at_a_glance/plots"
dat_dir = "/mnt/WanChai/Dropbox/GITHUB_REPO/Robinhood_at_a_glance/robintrack_popularity_export"
dat_dir = "/mnt/WanChai/Dropbox/AlgoTrading/Robinhood/robintrack_popularity_export"
setwd(home)
source(paste(utils, "/Fun.R", sep=""))
nm = list.files(path=dat_dir, all.files=FALSE, include.dirs=FALSE)
nm = nm[3:length(nm)]
(N = length(nm))
head(nm)
tkr = sapply(strsplit(x=nm, split="\\."), parse_ticker)
# Check
sum(is.na(tkr)) # expect 0
head(tkr)
tail(tkr)
grep(pat="\\.", tkr)
ix = grep(pat="\\.", tkr)
tkr[ix]
# Read CSV files, convert them to xts objects, save them to the data_env environment
setwd(dat_dir)
data_env = new.env()
res = sapply(nm, read_convert_save2env, data_env=data_env)
len(res)
length(res)
# Check
len(ls(envir=data_env)) == len(nm) # expect TRUE
# Check
length(ls(envir=data_env)) == length(nm) # expect TRUE
setwd(home)
xx = data_env$TSLA
head(xx)
colnames(xx)
colnames(xx) = "TSLA"
head(xx)
rm(data_env)
ls()
data_env = new.env()
res = sapply(nm, read_convert_save2env, data_env=data_env)
ls()
ls(envir=data_env)
head(nm)
source(paste(utils, "/Fun.R", sep=""))
res = sapply(nm, read_convert_save2env, data_env=data_env)
head(nm)
read_convert_save2env(nm[1000], data_env)
getwd()
# Read CSV files, convert them to xts objects, save them to the data_env environment
setwd(dat_dir)
res = sapply(nm, read_convert_save2env, data_env=data_env)
head(res)
# Check
length(ls(envir=data_env)) == length(nm) # expect TRUE
X11();hist(res)
summary(res)
which(res > 30000)
head(data_env$EBR)
dim(data_env$EBR)
tail(data_env$EBR)
which(res > 20000)
which(res > 19000)
which(res > 18000)
which(res > 17000)
which(res > 18000)
ix = which(res > 18000)
res[ix]
setwd(home)
source(paste(utils, "/Fun.R", sep=""))
setwd(home)
# Aggregate the hourly data to daily and weekly and put them in a list
ll = sweep_env(data_env, day_wk_aggregator)
len(ll)
library(goodies)
len(ll)
str(ll[[1000]])
head(ll[1000]["y_daily"])
head(ll[1000][["y_daily"]])
head(ll[1000]$y_daily)
xx=ll[1000]
str(xx)
head(xx$y_daily)
len(xx)
head(xx[[1]]$y_daily)
head(xx[[1]]$dy_daily)
head(xx[[1]]$dy_wk)
# Check + statistics on each ticker dataset
cnt = table(sapply(ll, function(.s) nrow(.s[["y_daily"]])))
head(cnt)
len(cnt)
cnt
# [1] 0.8450455
# ==> 84% of the tickers have more than 1 yr of data
table(sapply(ll, function(.s) nrow(.s[["dy_daily"]])))
cnt = table(sapply(ll, function(.s) nrow(.s[["y_wk"]])))
sum(cnt[which(as.integer(names(cnt)) > 52)]) / len(tkr)
# [1] 0.8488
# ==> 84% of the tickers have more than 52 wks of data
table(sapply(ll, function(.s) nrow(.s[["dy_wk"]])))
head(xx)
str(xx)
xx = xx[[1]][["y_daily"]]
head(xx)
colnames(xx)
source(paste(utils, "/Fun.R", sep=""))
# 2. Top holdings
df = as.data.frame(t(sapply(ll, latest_stat)))
head(df)
sapply(df, class)
df[,"tkr"] = as.character(df[,"tkr"])
df[,"base_holding"] = as.numeric(df[,"base_holding"])
df[,"cur_holding"] = as.numeric(df[,"cur_holding"])
df[,"pct_change"] = 100*(df[,"cur_holding"] / df[,"base_holding"] - 1)
df = df[order(df[,"cur_holding"], decreasing = TRUE),]
top_nm = head(df, 10)[,"tkr"]
top_nm
head(df, 30)
# 3. stocks with more than 100k accounts
df[which(df[,"cur_holding"] > 100000), "tkr"]
# 4. largest percentage increase since Mar 20
df1 = head(df, 100)
df1 = df1[order(df1[,"pct_change"], decreasing=TRUE),]
incr_nm = head(df1, 10)[,"tkr"]
incr_nm
# 4.1 largest percentage decrease since Mar 20
df2 = df[which(df[,"pct_change"] < 0 & df[,"base_holding"] > 10000),]
dim(df2)
df2 = df2[order(df2[,"pct_change"], decreasing =FALSE),]
decr_nm = head(df2, 10)[,"tkr"]
decr_nm
# 2. Top holdings
df = as.data.frame(t(sapply(ll, latest_stat, "2020-03-20")))
head(df)
df[,"tkr"] = as.character(df[,"tkr"])
df[,"base_holding"] = as.numeric(df[,"base_holding"])
df[,"cur_holding"] = as.numeric(df[,"cur_holding"])
df[,"pct_change"] = 100*(df[,"cur_holding"] / df[,"base_holding"] - 1)
df = df[order(df[,"cur_holding"], decreasing = TRUE),]
top_nm = head(df, 10)[,"tkr"]
top)nm
top_nm
head(df)
head(df, 30)
# 3. stocks with more than 100k accounts
df[which(df[,"cur_holding"] > 100000), "tkr"]
# 4. largest percentage increase since Mar 20
df1 = head(df, 100)
df1 = df1[order(df1[,"pct_change"], decreasing=TRUE),]
incr_nm = head(df1, 10)[,"tkr"]
incr_nm
head(df1, 10)
head(df1, 20)
xx = ll[[1000]][[1]][["y_daily"]]
xx = ll[[1000]][["y_daily"]]
head(xx)
colnames(xx)
colnames(xx)[1]
xx["2020-03-20"]
mean(xx["2020-03-20"])
xx = ll[[2000]][["y_daily"]]
head(xx)
mean(xx["2020-03-20"])
xx["2020-03-20"]
data_env$AAPL["2020-03-20"]
mean(data_env$AAPL["2020-03-20"])
which(ls(envir = data_env) == "AAPL")
xx=ll[[15]]
str(xx)
xx = xx[[1]][["y_daily"]]
xx = xx[["y_daily"]]
head(xx)
xx["2020-03-20"]
# 2. Top holdings
df = as.data.frame(t(sapply(ll, latest_stat, "2020-03-20")))
df[,"tkr"] = as.character(df[,"tkr"])
df[,"base_holding"] = as.numeric(df[,"base_holding"])
df[,"cur_holding"] = as.numeric(df[,"cur_holding"])
df[,"pct_change"] = 100*(df[,"cur_holding"] / df[,"base_holding"] - 1)
df = df[order(df[,"cur_holding"], decreasing = TRUE),]
head(df, 10)
# 5. largest percentage increase since Jun 1
df3 = as.data.frame(t(sapply(ll, latest_stat, "2020-06-01")))
df3[,"tkr"] = as.character(df3[,"tkr"])
df3[,"base_holding"] = as.numeric(df3[,"base_holding"])
df3[,"cur_holding"] = as.numeric(df3[,"cur_holding"])
df3[,"pct_change"] = 100*(df3[,"cur_holding"] / df3[,"base_holding"] - 1)
df3 = df3[order(df3[,"cur_holding"], decreasing = TRUE),]
df4 = head(df3, 100)
df4
df4 = df4[order(df4[,"pct_change"], decreasing=TRUE),]
head(df4, 20)
head(df1, 10)
# 2. Top holdings
df = as.data.frame(t(sapply(ll, latest_stat, "2020-03-20")))
df[,"tkr"] = as.character(df[,"tkr"])
df[,"base_holding"] = as.numeric(df[,"base_holding"])
df[,"cur_holding"] = as.numeric(df[,"cur_holding"])
df[,"pct_change"] = 100*(df[,"cur_holding"] / df[,"base_holding"] - 1)
df = df[order(df[,"cur_holding"], decreasing = TRUE),]
top_nm = head(df, 10)[,"tkr"]
top_nm
# 3. stocks with more than 100k accounts
df[which(df[,"cur_holding"] > 100000), "tkr"]
# 4. largest percentage increase since Mar 20
df1 = head(df, 100)
df1 = df1[order(df1[,"pct_change"], decreasing=TRUE),]
incr_nm = head(df1, 10)[,"tkr"]
incr_nm
head(df1, 10)
head(df, 10)
incr_nm
for (s in incr_nm) getSymbols(s, env=globalenv(), src="yahoo", from="1800-01-01")
# Time Series Plots (one yr)
setwd(plot_dir)
png("Largest_incr.png", width = 1080, height=640)
par(mfrow=c(3,4), mar=c(2,2,2,2))
for ( s in incr_nm ) {
ix = which(tkr == s)
y = ll[[ix]]$y_daily["2019-06::"]
df3 = data.frame(date=as.Date(index(y)), y=as.numeric(y))
y1 = get(s)["2019-06::", 6]
df4 = data.frame(date=index(y1), y1=as.numeric(y1))
df5 = merge(x=df3, y=df4, by="date", all.x=FALSE, all.y=TRUE)
tick.loc = as.integer(seq.int(from=1, to=nrow(df5), length.out=10))
plot(y~date, data=df5, xlab="", ylab="", xaxt="n", type="l", lwd=5, col="red", main=s)
par(new=TRUE)
plot(y1~date, data=df5, xlab="", ylab="", xaxt="n", yaxt="n", type="l", lwd=1, col="blue" )
axis(1, at=df5[tick.loc,"date"], labels=format(df5[tick.loc,"date"], "%b-%d"), cex.axis=0.6)
}
dev.off()
# 4.1 largest percentage decrease since Mar 20
df2 = df[which(df[,"pct_change"] < 0 & df[,"base_holding"] > 10000),]
dim(df2)
df2 = df2[order(df2[,"pct_change"], decreasing =FALSE),]
decr_nm = head(df2, 10)[,"tkr"]
head(df2, 10)
df2
decr_nm
for (s in decr_nm) getSymbols(s, env=globalenv(), src="yahoo", from="1800-01-01")
# Time Series Plots (one yr)
setwd(plot_dir)
png("Largest_decr.png", width = 1080, height=640)
par(mfrow=c(3,4), mar=c(2,2,2,2))
for ( s in decr_nm ) {
ix = which(tkr == s)
y = ll[[ix]]$y_daily["2019-06::"]
df3 = data.frame(date=as.Date(index(y)), y=as.numeric(y))
y1 = get(s)["2019-06::", 6]
df4 = data.frame(date=index(y1), y1=as.numeric(y1))
df5 = merge(x=df3, y=df4, by="date", all.x=FALSE, all.y=TRUE)
tick.loc = as.integer(seq.int(from=1, to=nrow(df5), length.out=10))
plot(y~date, data=df5, xlab="", ylab="", xaxt="n", type="l", lwd=5, col="red", main=s)
par(new=TRUE)
plot(y1~date, data=df5, xlab="", ylab="", xaxt="n", yaxt="n", type="l", lwd=1, col="blue" )
axis(1, at=df5[tick.loc,"date"], labels=format(df5[tick.loc,"date"], "%b-%d"), cex.axis=0.6)
}
dev.off()
setwd(home)
save.image("Robintrack.RData")
ls()
ls
head(xx)
class(xx)
xt = data_env$AAPL
head(xt)
head(xt,50)
tail(xt,50)
td = index(xt)
len(td)
dim(xt)
head(td)
dtd = diff(td)
head(dtd)
X11();hist(dtd)
X11();hist(as.integer(dtd))
summary(dtd)
summary(as.integer(dtd))
X11();hist(log(as.integer(dtd)))
X11();hist(log10(as.integer(dtd)))
log10(3600)
X11();hist(log10(as.integer(dtd)), breaks=50)
which(dtd > 3700)
ix = which(dtd > 3700)
xt[ix, ]
xt[ix.more(ix), ]
head(xt[ix.more(ix), ])
head(xt[ix.more(ix), ], 30)
ix = which(dtd > 3600*3)
ix
head(xt[ix.more(ix), ], 30)
xt[105:120,]
xt[15610:15630,]
summary(dtd)
summary(as.integer(dtd))
tdt = index(xt)
dtdt = as.integer(diff(tdt))
head(dtdt)
class(dtdt)
summary(dtdt)
quantile(dtdt, prob=c(0.01, 0.99))
quantile(dtdt, prob=c(0.01, 0.99))[1]
quantile(dtdt, prob=c(0.01, 0.99))[2]
quantile(dtdt, prob=0.99)
q99=quantile(dtdt, prob=0.99)
q99
which(dtdt > q99)
ix=which(dtdt > q99)
5132/3600
ix=which(dtdt > 5*3600)
ix
ix=which(dtdt > 24*3600)
ix
xt[ix.more(ix),]
ix["2018-08"]
ix["2018-08",]
ix["2018-08"]
xt["2018-08"]
xt["2018-08-06::2018-08-09"]
summary(dtdt)
sd(dtdt)
X11();plot(dtdt, type="l")
getwd()
save.image("Robintrack.RData")
